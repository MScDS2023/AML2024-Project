{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from datasets import load_dataset\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('GonzaloA/fake_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = {0: [], 1: []}\n",
    "\n",
    "for i, article in enumerate(data['train']):\n",
    "    split[article['label']].append({'text': article['text'], 'index': i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_fake = ' '.join(split[0])\n",
    "#all_true = ' '.join(split[1])\n",
    "\n",
    "\n",
    "fake_counts = defaultdict(lambda: {'count': 0, 'articles': []})\n",
    "for article_dict in split[0]:\n",
    "    text = article_dict['text']\n",
    "    index = article_dict['index']\n",
    "    tokens = word_tokenize(text)\n",
    "    for token in tokens:\n",
    "        fake_counts[token]['count'] += 1\n",
    "        fake_counts[token]['articles'].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true = ' '.join([article['text'] for article in split[1]])\n",
    "true_tokens = word_tokenize(all_true)\n",
    "true_amounts = Counter(true_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tf = {}\n",
    "\n",
    "for token in fake_counts:\n",
    "    count = fake_counts[token]['count']\n",
    "    articles = fake_counts[token]['articles']\n",
    "    if token in true_amounts:\n",
    "        fake_tf[token] = [count / true_amounts[token], articles]\n",
    "    else:\n",
    "        fake_tf[token] = [count, articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = sorted(list(fake_tf.items()), key=lambda x: x[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sorted_:\n",
    "    print(token[0], token[1][0], token[1][1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('fake_tokens.txt', 'a') as f:\n",
    "#    for token in sorted_:\n",
    "#        f.write(f'{token[0]}, {token[1][0]}, {token[1][1][:10]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_NE = []\n",
    "real_NE = []\n",
    "\n",
    "length = len(data['train'])\n",
    "\n",
    "for i, article in enumerate(data['train']):\n",
    "    print(f'{i} / {length}')\n",
    "    tags = pos_tag(word_tokenize(article['text']))\n",
    "    chunks = ne_chunk(tags)\n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            if article['label'] == 0:\n",
    "                fake_NE.append(' '.join([word[0] for word in chunk]))\n",
    "            else:\n",
    "                real_NE.append(' '.join([word[0] for word in chunk]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
