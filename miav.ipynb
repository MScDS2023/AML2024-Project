{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.git',\n",
       " '.gitignore',\n",
       " 'fake_tokens.txt',\n",
       " 'main.ipynb',\n",
       " 'miav.ipynb',\n",
       " 'notebook.ipynb',\n",
       " 'predictions',\n",
       " 'README.md',\n",
       " 'related_work.ipynb',\n",
       " 'test_trainer',\n",
       " 'tmp_trainer',\n",
       " 'words']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection on fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake news has many definitions, ranging from being factually incorrect to misleading, which makes it hard when quantifying results and cross examining results between different studies, since the latent space can be different dependent on the definition of the task. The problem with using objective truth as the definition, that truth can vary depending on culture and context. An actor in a conflict can be seen as the good freedome fighter towards an opressive regime by one side, and as a terrorist on the other side. Lastly, the truth can also change over time, which means that models have to be retrained with up to date information constantly to be able to combat the fake news within the catagory factual correct. Using the definition of misleading would be an inherently easier task since the model would not have to have a world view in order to classify. It should be solveable by using information only present in the text and comparing that to the title. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Recent studies have shown that fake news propagates through social media at unprecedented speeds. This was observed to happen during the emergence of COVID-19, thus the need to quickly detect and mitigate the spreading of fake news is more important than ever s[1]. \n",
    "\n",
    "Many definitions are presented, ranging from being factually incorrect to misleading, and unfortunately, our data source has not specified which definition they use. This makes it harder to interpret why a model predicted as it did, since we do not know if the data contains mostly stories conflicting with reality, or simply written by an overselling journalist. -->\n",
    "\n",
    "Related work\n",
    "This paper, written by Shaina Raza & Chen Ding, uses META's BART language model trained on two data sets: NELA-GT-19, which are news articles sourced from multiple sites, and Fakeddit, which is a multimodal dataset from Reddit, consisting of both images and text. The datasets used had more than a binary score, it included labels such as mixed, which is when there is a disagrement whether something is true or false, and categories such as satire into a single category Fake. They discuss their approach of continuously updating the model's training data to retrain the model and stay on top of relevant news. They also assert that freezing a model's weights can quickly make the model outdated since they don't generalize well to future events. Finally, they report an accuracy of 74.89%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s[1] = https://link.springer.com/article/10.1007/s41060-021-00302-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s[2] = https://arxiv.org/pdf/2101.00180.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
